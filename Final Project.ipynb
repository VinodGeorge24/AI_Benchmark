{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae6aac8-0833-49da-87eb-07b8113aa1be",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09c35a6-f2f1-4310-a267-83854f68c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\willk\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06e9a94-178b-49bb-993c-c2e0b96c01c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Organization categorization</th>\n",
       "      <th>Country (from Organization)</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>...</th>\n",
       "      <th>Finetune compute notes</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Model accessibility</th>\n",
       "      <th>Training code accessibility</th>\n",
       "      <th>Inference code accessibility</th>\n",
       "      <th>Accessibility notes</th>\n",
       "      <th>Frontier model</th>\n",
       "      <th>Training power draw (W)</th>\n",
       "      <th>Training compute estimation method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXAONE Deep 32B</td>\n",
       "      <td>Language</td>\n",
       "      <td>LG AI Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Korea (Republic of)</td>\n",
       "      <td>LG AI Research, Kyunghoon Bae, Eunbi Choi, Kib...</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>EXAONE Deep: LLMs with Enhanced Reasoning Perf...</td>\n",
       "      <td>https://arxiv.org/abs/2503.12524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Table 1 (reported): 7.04 × 10^21 FLOP\\n\\n6ND =...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Open weights (non-commercial)</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/LGAI-EXAONE/EXAONE-Deep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.883066e+05</td>\n",
       "      <td>Reported,Operation counting,Hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QwQ-32B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>Industry</td>\n",
       "      <td>China</td>\n",
       "      <td>Qwen Team</td>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>QwQ-32B: Embracing the Power of Reinforcement ...</td>\n",
       "      <td>https://qwenlm.github.io/blog/qwq-32b/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Open weights (unrestricted)</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/Qwen/QwQ-32B\\nApache 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Foundational contributors\\nAlex Paino, Ali Kam...</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>Introducing GPT-4.5</td>\n",
       "      <td>https://openai.com/index/introducing-gpt-4-5/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API access</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>Industry</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-7-sonnet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API access</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grok-3</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>xAI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Grok 3 Beta — The Age of Reasoning Agents</td>\n",
       "      <td>https://x.ai/blog/grok-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hosted access (no API)</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.540037e+08</td>\n",
       "      <td>Hardware,Comparison with other models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model                      Domain    Organization  \\\n",
       "0    EXAONE Deep 32B                    Language  LG AI Research   \n",
       "1            QwQ-32B                    Language         Alibaba   \n",
       "2            GPT-4.5  Language,Vision,Multimodal          OpenAI   \n",
       "3  Claude 3.7 Sonnet  Language,Vision,Multimodal       Anthropic   \n",
       "4             Grok-3  Language,Vision,Multimodal             xAI   \n",
       "\n",
       "  Organization categorization Country (from Organization)  \\\n",
       "0                    Industry         Korea (Republic of)   \n",
       "1                    Industry                       China   \n",
       "2                    Industry    United States of America   \n",
       "3                    Industry    United States of America   \n",
       "4                    Industry    United States of America   \n",
       "\n",
       "                                             Authors Publication date  \\\n",
       "0  LG AI Research, Kyunghoon Bae, Eunbi Choi, Kib...       2025-03-16   \n",
       "1                                          Qwen Team       2025-03-06   \n",
       "2  Foundational contributors\\nAlex Paino, Ali Kam...       2025-02-27   \n",
       "3                                                NaN       2025-02-24   \n",
       "4                                                NaN       2025-02-17   \n",
       "\n",
       "                                           Reference  \\\n",
       "0  EXAONE Deep: LLMs with Enhanced Reasoning Perf...   \n",
       "1  QwQ-32B: Embracing the Power of Reinforcement ...   \n",
       "2                                Introducing GPT-4.5   \n",
       "3                                  Claude 3.7 Sonnet   \n",
       "4          Grok 3 Beta — The Age of Reasoning Agents   \n",
       "\n",
       "                                               Link  Citations  ...  \\\n",
       "0                  https://arxiv.org/abs/2503.12524        NaN  ...   \n",
       "1            https://qwenlm.github.io/blog/qwq-32b/        NaN  ...   \n",
       "2     https://openai.com/index/introducing-gpt-4-5/        NaN  ...   \n",
       "3  https://www.anthropic.com/news/claude-3-7-sonnet        NaN  ...   \n",
       "4                          https://x.ai/blog/grok-3        NaN  ...   \n",
       "\n",
       "                              Finetune compute notes Batch size  \\\n",
       "0  Table 1 (reported): 7.04 × 10^21 FLOP\\n\\n6ND =...        NaN   \n",
       "1                                                NaN        NaN   \n",
       "2                                                NaN        NaN   \n",
       "3                                                NaN        NaN   \n",
       "4                                                NaN        NaN   \n",
       "\n",
       "   Batch size notes            Model accessibility  \\\n",
       "0               NaN  Open weights (non-commercial)   \n",
       "1               NaN    Open weights (unrestricted)   \n",
       "2               NaN                     API access   \n",
       "3               NaN                     API access   \n",
       "4               NaN         Hosted access (no API)   \n",
       "\n",
       "   Training code accessibility Inference code accessibility  \\\n",
       "0                   Unreleased                          NaN   \n",
       "1                   Unreleased                          NaN   \n",
       "2                   Unreleased                          NaN   \n",
       "3                   Unreleased                          NaN   \n",
       "4                   Unreleased                          NaN   \n",
       "\n",
       "                                 Accessibility notes Frontier model  \\\n",
       "0  https://huggingface.co/LGAI-EXAONE/EXAONE-Deep...            NaN   \n",
       "1      https://huggingface.co/Qwen/QwQ-32B\\nApache 2            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4                                                NaN            NaN   \n",
       "\n",
       "   Training power draw (W)     Training compute estimation method  \n",
       "0             7.883066e+05   Reported,Operation counting,Hardware  \n",
       "1                      NaN                                    NaN  \n",
       "2                      NaN                                    NaN  \n",
       "3                      NaN                                    NaN  \n",
       "4             1.540037e+08  Hardware,Comparison with other models  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('notable_ai_models.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66453536-a6c6-4ac9-be1e-aa40f1adff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 924 entries, 0 to 923\n",
      "Data columns (total 42 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Model                               924 non-null    object \n",
      " 1   Domain                              923 non-null    object \n",
      " 2   Organization                        911 non-null    object \n",
      " 3   Organization categorization         911 non-null    object \n",
      " 4   Country (from Organization)         911 non-null    object \n",
      " 5   Authors                             874 non-null    object \n",
      " 6   Publication date                    923 non-null    object \n",
      " 7   Reference                           911 non-null    object \n",
      " 8   Link                                921 non-null    object \n",
      " 9   Citations                           752 non-null    float64\n",
      " 10  Notability criteria                 924 non-null    object \n",
      " 11  Notability criteria notes           475 non-null    object \n",
      " 12  Parameters                          614 non-null    float64\n",
      " 13  Parameters notes                    566 non-null    object \n",
      " 14  Training compute (FLOP)             468 non-null    float64\n",
      " 15  Training compute notes              518 non-null    object \n",
      " 16  Training dataset                    513 non-null    object \n",
      " 17  Training dataset notes              327 non-null    object \n",
      " 18  Training dataset size (datapoints)  497 non-null    float64\n",
      " 19  Dataset size notes                  506 non-null    object \n",
      " 20  Epochs                              239 non-null    float64\n",
      " 21  Training time (hours)               212 non-null    float64\n",
      " 22  Training time notes                 216 non-null    object \n",
      " 23  Training hardware                   301 non-null    object \n",
      " 24  Hardware quantity                   188 non-null    float64\n",
      " 25  Hardware utilization                41 non-null     float64\n",
      " 26  Training compute cost (2023 USD)    155 non-null    float64\n",
      " 27  Compute cost notes                  26 non-null     object \n",
      " 28  Confidence                          664 non-null    object \n",
      " 29  Abstract                            639 non-null    object \n",
      " 30  Base model                          95 non-null     object \n",
      " 31  Finetune compute (FLOP)             37 non-null     float64\n",
      " 32  Finetune compute notes              53 non-null     object \n",
      " 33  Batch size                          86 non-null     float64\n",
      " 34  Batch size notes                    65 non-null     object \n",
      " 35  Model accessibility                 487 non-null    object \n",
      " 36  Training code accessibility         425 non-null    object \n",
      " 37  Inference code accessibility        200 non-null    object \n",
      " 38  Accessibility notes                 311 non-null    object \n",
      " 39  Frontier model                      144 non-null    object \n",
      " 40  Training power draw (W)             176 non-null    float64\n",
      " 41  Training compute estimation method  441 non-null    object \n",
      "dtypes: float64(12), object(30)\n",
      "memory usage: 303.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c090f5-770b-42cf-a09a-9996eb84f479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
